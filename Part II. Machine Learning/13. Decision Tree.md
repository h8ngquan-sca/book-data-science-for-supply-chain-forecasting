
<img width="2752" height="1536" alt="tree_info" src="https://github.com/user-attachments/assets/e80c648f-6088-4a12-8b24-a77eab2460a4" />

# Khái niệm

**Cây quyết định (Decision Tree)** là một thuật toán học máy (machine learning algorithm) xây dựng sơ đồ các câu hỏi (hình một cái cây) để thực hiện dự đoán.

**Phân loại**
Dựa trên kiểu dữ liệu kết quả đầu ra, có thể chia Decision Tree thành 2 phân loại:
Tiếp tục với phương pháp Feynman, chúng ta hãy nhớ lại trò chơi **"20 Câu Hỏi"** ở trên.
**1/ Classification Tree (Cây phân loại)**
**Câu hỏi cốt lõi:** "Nó thuộc nhóm nào?" hoặc "Chuyện gì sẽ xảy ra?" 
**Kết quả**: một **Nhãn/Danh mục**).
Hãy tưởng tượng bạn đang phân loại các chuyến xe giao hàng. Bạn đặt ra các câu hỏi ở các Nút (Node):
- _Trời có đang mưa to không?_ (Có/Không)
- _Tài xế có đi qua tuyến đường X đang thi công không?_ (Có/Không)
Khi đi đến cuối cành cây (Lá), kết quả bạn nhận được sẽ là một nhãn dán cụ thể: **"Đúng giờ"** hoặc **"Trễ hẹn"**.
Cây phân loại giống như một người thủ thư. Nó nhìn vào các đặc điểm của một cuốn sách (dữ liệu) và quyết định xem nên cất nó vào kệ "Tiểu thuyết", "Khoa học" hay "Lịch sử". Kết quả luôn là những nhóm rời rạc, không có trạng thái lấp lửng ở giữa.

**2/ Regression Tree (Cây hồi quy)**
**Câu hỏi cốt lõi:** "Bao nhiêu?"
**Kết quả**: một **Con số cụ thể**).
Lần này, bạn chuyển sang bộ phận Demand Planning (Lập kế hoạch nhu cầu) và cần dự báo số lượng hàng hóa. Bạn vẫn dùng cây quyết định để đặt câu hỏi:
- _Sắp tới có phải là chiến dịch Sale siêu sale (như 12.12) không?_ (Có/Không)
- _Sản phẩm này có đang chạy quảng cáo trên trang chủ không?_ (Có/Không)
Khi đi đến cuối cành cây (Lá), thay vì nhận được một nhãn dán, bạn nhận được một con số dự báo: **"Sẽ bán được 1,250 đơn vị"**.
Cây hồi quy giống như một chuyên gia định giá bất động sản. Nó sẽ nhìn vào các đặc trưng (diện tích, hẻm xe hơi, quận nào) và ở điểm cuối cùng, nó tính toán trung bình giá của các ngôi nhà tương tự trong quá khứ để đưa ra cho bạn một con số dự báo: "Ngôi nhà này đáng giá 3.5 tỷ".

**Tóm lại:**
- **Classification Tree:** Dùng để phân chia mọi thứ vào các "chiếc hộp" có tên gọi rõ ràng (Đạt/Không đạt, Xanh/Đỏ, Gian lận/Hợp lệ). Dữ liệu đầu ra là định tính.
- **Regression Tree:** Dùng để đoán một giá trị liên tục trên một thước đo (Bao nhiêu tiền, Mấy giờ, Số lượng bao nhiêu). Dữ liệu đầu ra là định lượng.

# Thành phần của Decision Tree:

Cấu trúc của Decision Tree bao gồm:

**1/ Đặc trưng (Feature)**
Đặc trưng là **dữ liệu đầu vào** dùng để đặt ra các câu hỏi. Nếu không có manh mối, không thể ra quyết định.
Trong ví dụ về kho hàng, các "đặc trưng" (manh mối) của có thể là:
- _Số lượng tồn kho hiện tại_ (Current Inventory)
- _Dự báo nhu cầu tuần tới_ (Forecasted Demand)
- _Thời gian chờ hàng về_ (Lead Time)

Thuật toán học máy (Machine Learning) sẽ nhìn vào tất cả các "đặc trưng" này để tìm ra câu hỏi nào quan trọng nhất cần hỏi đầu tiên.

**2/ Nút (Node)**
Nút chính là **ngã ba đường**, nơi dùng một "Đặc trưng" để **đặt ra một câu hỏi cụ thể** nhằm chia nhỏ dữ liệu.
- **Nút gốc (Root Node):** Đây là câu hỏi quan trọng nhất, nằm trên cùng của cây. Ví dụ: _"Số lượng tồn kho hiện tại có dưới 50 đơn vị không?"_
    - Nếu **Có** -> Rẽ sang nhánh bên trái.
    - Nếu **Không** -> Rẽ sang nhánh bên phải.
- **Các Nút trung gian (Internal Nodes):** Là các câu hỏi tiếp theo sau khi đã rẽ nhánh. Ví dụ ở nhánh bên phải, tiếp tục hỏi một Nút mới: _"Dự báo nhu cầu tuần tới có lớn hơn 100 đơn vị không?"_

Mỗi liên tục phân loại các tình huống cho đến khi mọi thứ rành mạch.

**4/ Lá (Leaf)**
Lá là **điểm dừng chân cuối cùng**, nơi không còn ngã ba nào nữa và bạn **nhận được kết quả/quyết định**. Nó được gọi là "lá" vì nó nằm ở tận cùng của các nhánh cây.
Sau khi đi qua một loạt các câu hỏi (Nút), sẽ rơi vào một chiếc Lá.
- _Lá 1:_ "Đặt thêm 200 đơn vị ngay lập tức".
- _Lá 2:_ "Không cần đặt thêm, chờ đến tuần sau".
# Cơ chế hoạt động

Thuật toán bắt đầu từ tập dữ liệu lớn và liên tục đặt ra các câu hỏi Có/Không (ví dụ: "Nhu cầu tháng trước có > 7 không?") để chia nhỏ dữ liệu.

**Mục tiêu của câu hỏi:** Một câu hỏi (split) được đánh giá là "tốt" nếu nó giúp giảm thiểu tối đa sai số dự báo trong các tập dữ liệu con (các lá) vừa được chia ra

# Rủi ro Quá khớp (Overfitting) và Các tham số kiểm soát
Nếu không bị giới hạn, cây sẽ tiếp tục mọc (đặt câu hỏi) cho đến khi mỗi quan sát thực tế nằm ở một lá riêng biệt. Điều này dẫn đến sự hoàn hảo ảo trên tập huấn luyện nhưng lại dự báo sai bét trên dữ liệu mới (Overfitting). Để ngăn chặn điều này, cần thiết lập các giới hạn (Parameters):

**1/ `max_depth` (Chiều sâu tối đa)**

Là **số lượng câu hỏi tối đa** được phép hỏi liên tiếp nhau trước khi bắt buộc phải đưa ra quyết định.

**Ví dụ:** Thay vì hỏi lan man 20 câu mới quyết định được một đơn hàng có cần giao gấp không, giới hạn chỉ cho phép _"hỏi tối đa 3 câu thôi (`max_depth = 3`). Nút gốc là câu 1, rẽ nhánh thêm 2 lần nữa"_.
**Tác dụng:** Giữ cho quá trình ra quyết định ngắn gọn, dễ kiểm soát và mang tính tổng quát cao. 

**2/ `min_samples_split` (Số lượng mẫu tối thiểu để chia nhánh)**

**Số lượng mẫu tối thiểu** cần có trong một Nút để được phép tiếp tục chia tách
**Tác dụng:** Ngăn cây quyết định chẻ nhỏ dữ liệu thành những nhóm quá vụn vặt, không mang lại giá trị vận hành thực tế.

**3/ `min_samples_leaf` (Số lượng mẫu tối thiểu ở một Lá)**

Là một kết luận chốt hạ (chiếc Lá) chỉ được tồn tại nếu nó bao trùm được **một số lượng đối tượng tối thiểu**. Nếu không, nhát cắt tạo ra nó sẽ bị hủy bỏ.

**Ví dụ:** Khi lập chính sách cho hàng tồn kho, khi nhìn vào kết quả ở chiếc Lá cuối cùng, quy luật đó rốt cuộc chỉ áp dụng cho đúng **1 mã SKU** ế ẩm duy nhất trong tổng số hàng ngàn sản phẩm. Điều này gần như không có giá trị gì trong thực tế vận hành
Nếu cài đặt `min_samples_leaf = 10`, có nghĩa là _"Một kết luận (Leaf) phải đại diện cho ít nhất 10 mã hàng"_
**Tác dụng:** Đảm bảo mọi quyết định cuối cùng đều có đủ sức nặng thống kê, tránh tạo ra những quy tắc riêng biệt cho các trường hợp ngoại lệ (outliers).
